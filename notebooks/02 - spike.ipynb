{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orcapod as op\n",
    "from demo_setup.config import namespace_lookup, data_dir, store_dir, orch, client\n",
    "import demo_setup.util as demo_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e0ebb",
   "metadata": {},
   "source": [
    "## Orcapod DEMO\n",
    "\n",
    "A framework for fully traceable and reproducible scientific computation\n",
    "\n",
    "## Guiding Principles\n",
    "\n",
    "- Reproducibility\n",
    "- Performance\n",
    "- Simplicity\n",
    "- Flexibility\n",
    "- Extensibility\n",
    "- Reusability\n",
    "- Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9ce09",
   "metadata": {},
   "source": [
    "## Monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor active containers\n",
    "\n",
    "# watch -n 0.5 docker ps -a\n",
    "\n",
    "\n",
    "# monitor agent communication network\n",
    "\n",
    "# clear && python -c 'import asyncio; import orcapod as op; client = op.AgentClient(group=\"demo\", host=\"alpha\"); asyncio.run(client.watch(key_expr=\"**\"))'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d304154",
   "metadata": {},
   "source": [
    "## Setup test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66381e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ff4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = Path(namespace_lookup[\"default\"]) / data_dir / \"configs\"\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save parameter files\n",
    "params = {\n",
    "    \"filter_width\": 3,\n",
    "    \"spike_threshold\": 3.0,\n",
    "    \"error_threshold\": 100.0,\n",
    "}\n",
    "with open(config_dir / \"1.json\", \"w\") as f:\n",
    "    json.dump(params, f, indent=2)\n",
    "\n",
    "params.update({\"filter_width\": 4})\n",
    "\n",
    "with open(config_dir / \"2.json\", \"w\") as f:\n",
    "    json.dump(params, f, indent=2)\n",
    "\n",
    "NUM_FILES = 3  # Later, increase to see error\n",
    "ERROR_SUBJ = 4\n",
    "\n",
    "\n",
    "# Generate a dummy ephys trace\n",
    "def generate_dummy_trace(n_samples=12, seed=0):\n",
    "    random.seed(seed)\n",
    "\n",
    "    noise = [random.gauss(0, 0.5) for _ in range(n_samples)]\n",
    "    spike_train = [0.0] * n_samples\n",
    "    for _ in range(seed + 1):\n",
    "        spike_idx = random.randrange(n_samples)\n",
    "        spike_train[spike_idx] = 10  # fake spike\n",
    "    trace = [n + s for n, s in zip(noise, spike_train)]\n",
    "\n",
    "    if seed % 2 == 1:  # For demonstrating speed variance\n",
    "        trace[0] = 1.0\n",
    "    if seed == ERROR_SUBJ:  # For later error detection\n",
    "        trace[3] = 999.0\n",
    "\n",
    "    return trace\n",
    "\n",
    "\n",
    "input_dir = Path(namespace_lookup[\"default\"]) / data_dir / \"subjects\"\n",
    "input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(1, NUM_FILES + 1):\n",
    "    trace = generate_dummy_trace(seed=i)\n",
    "    with open(input_dir / f\"{i}.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10123a8",
   "metadata": {},
   "source": [
    "## Define computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca3873",
   "metadata": {},
   "source": [
    "`smooth_pod` -  Simple computation that:\n",
    "- Loads a trace file\n",
    "- Loads a config file\n",
    "- Sleep for 10s if the first value is exactly `1`\n",
    "- Crash if any trace value is greater than `error_threshold`\n",
    "- Perform smoothing on the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ebedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_pod = op.Pod(\n",
    "    image=\"python:3.12-slim\",\n",
    "    command=[\n",
    "        \"bash\",\n",
    "        \"-c\",\n",
    "        \"umask u=rwx,g=rwx,o=rwx && python -c '{}'\".format(\n",
    "            dedent(\n",
    "                \"\"\"\n",
    "                import csv\n",
    "                import json \n",
    "                import statistics\n",
    "                from time import sleep\n",
    "                from pathlib import Path\n",
    "\n",
    "                for trace_file in Path(\"/tmp/input/traces\").glob(\"*\"):\n",
    "                    trace = [float(x) for row in csv.reader(trace_file.open()) for x in row if x.strip()]\n",
    "\n",
    "                    for config_file in Path(\"/tmp/input/configs\").glob(\"*\"):\n",
    "                        config = json.load(config_file.open())\n",
    "\n",
    "                        # Simulated error checks\n",
    "                        if trace and trace[0] == 1.0:\n",
    "                            sleep(10)\n",
    "                        if any(val > config.get(\"error_threshold\", float(\"inf\")) for val in trace):\n",
    "                            raise Exception(\"Intentional error\")\n",
    "\n",
    "                        # Moving average smoothing\n",
    "                        def moving_average(data, width=3):\n",
    "                            smoothed = []\n",
    "                            half = width // 2\n",
    "                            for i in range(len(data)):\n",
    "                                window = data[max(0, i - half) : min(len(data), i + half + 1)]\n",
    "                                smoothed.append(statistics.mean(window))\n",
    "                            return smoothed\n",
    "\n",
    "                        filter_width = config.get(\"filter_width\", 3)\n",
    "                        smoothed = moving_average(trace, filter_width)\n",
    "\n",
    "                        save_dir = f\"/tmp/output/config{config_file.stem}\"\n",
    "                        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "                        with open(f\"{save_dir}/subj_{trace_file.stem}.csv\", \"w\", newline=\"\") as smooth_file:\n",
    "                            writer = csv.writer(smooth_file)\n",
    "                            writer.writerow(smoothed)\n",
    "\n",
    "                        print(f\"Trace: {trace}\")\n",
    "                        print(f\"Config: {config}\")\n",
    "                        print(f\"Smoothed: {smoothed}\")\n",
    "                \"\"\"\n",
    "            ).strip()\n",
    "        ),\n",
    "    ],\n",
    "    input_spec={\n",
    "        \"traces\": op.PathInfo(path=\"/tmp/input/traces\", match_pattern=\".*\\.csv\"),\n",
    "        \"configs\": op.PathInfo(path=\"/tmp/input/configs\", match_pattern=\".*\\.json\"),\n",
    "    },\n",
    "    output_dir=\"/tmp/output/\",\n",
    "    output_spec={\"smooth\": op.PathInfo(path=\".\", match_pattern=\".*\\.csv\")},\n",
    "    source_commit_url=\"https://place.holder\",\n",
    "    recommended_cpus=0.1,\n",
    "    recommended_memory=100 << 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d535926",
   "metadata": {},
   "source": [
    "`spike_pod` -  Simple computation that:\n",
    "- Loads a trace file\n",
    "- Loads a config file\n",
    "- Finds/saves trace indices over `spike_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_pod = op.Pod(\n",
    "    image=\"python:3.13-slim\",\n",
    "    command=[\n",
    "        \"bash\",\n",
    "        \"-c\",\n",
    "        \"umask u=rwx,g=rwx,o=rwx && python -c '{}'\".format(\n",
    "            dedent(\n",
    "                \"\"\" \n",
    "                import csv\n",
    "                import json\n",
    "                from pathlib import Path\n",
    "\n",
    "                for trace_file in Path(\"/tmp/input/smooth\").glob(\"**/*.csv\"):\n",
    "                    trace = [float(x) for row in csv.reader(trace_file.open()) for x in row if x.strip()]\n",
    "\n",
    "                    for config_file in Path(\"/tmp/input/configs\").glob(\"*\"):\n",
    "                        config = json.load(config_file.open())\n",
    "\n",
    "                        spike_threshold = config.get(\"spike_threshold\", float(\"inf\"))\n",
    "                        print(f\"Trace: {trace}\")\n",
    "                        spikes = [i for i, val in enumerate(trace) if val > spike_threshold]\n",
    "\n",
    "                        save_dir = f\"/tmp/output/config{config_file.stem}\"\n",
    "                        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "                        with open(f\"{save_dir}/{trace_file.stem}.csv\", \"w\", newline=\"\") as spike_file:\n",
    "                            writer = csv.writer(spike_file)\n",
    "                            writer.writerow(spikes)\n",
    "\n",
    "                        print(f\"Spikes: {spikes}\")\n",
    "                \"\"\"\n",
    "            ).strip()\n",
    "        ),\n",
    "    ],\n",
    "    input_spec={\n",
    "        \"smooth\": op.PathInfo(path=\"/tmp/input/smooth\", match_pattern=\".*\\.csv\"),\n",
    "        \"configs\": op.PathInfo(path=\"/tmp/input/configs\", match_pattern=\".*\\.json\"),\n",
    "    },\n",
    "    output_dir=\"/tmp/output/\",\n",
    "    output_spec={\"spikes\": op.PathInfo(path=\".\", match_pattern=\".*\\.csv\")},\n",
    "    source_commit_url=\"https://place.holder\",\n",
    "    recommended_cpus=0.1,\n",
    "    recommended_memory=100 << 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46b905",
   "metadata": {},
   "source": [
    "## Run one-off compute job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_pod_job = op.PodJob(\n",
    "    pod=smooth_pod,\n",
    "    input_packet=op.Packet(\n",
    "        {\n",
    "            \"traces\": op.PathSet.COLLECTION(\n",
    "                blobs=[\n",
    "                    op.Blob(\n",
    "                        kind=op.BlobKind.FILE,\n",
    "                        location=op.Uri(\n",
    "                            namespace=\"default\",\n",
    "                            path=f\"{data_dir}/subjects/2.csv\",\n",
    "                        ),\n",
    "                        checksum=\"\",\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            \"configs\": op.PathSet.COLLECTION(\n",
    "                blobs=[\n",
    "                    op.Blob(\n",
    "                        kind=op.BlobKind.FILE,\n",
    "                        location=op.Uri(\n",
    "                            namespace=\"default\",\n",
    "                            path=f\"{data_dir}/configs/1.json\",\n",
    "                        ),\n",
    "                        checksum=\"\",\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        }\n",
    "    ),\n",
    "    output_dir=op.Uri(namespace=\"default\", path=f\"{data_dir}/smooth\"),\n",
    "    cpu_limit=0.1,\n",
    "    memory_limit=100 << 20,\n",
    "    namespace_lookup=namespace_lookup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4066fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_run = await orch.start(namespace_lookup=namespace_lookup, pod_job=smooth_pod_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51351f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_result = await orch.get_result(namespace_lookup=namespace_lookup, pod_run=pod_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "await orch.delete(pod_run=pod_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38768917",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_pod_job = op.PodJob(\n",
    "    pod=spike_pod,\n",
    "    input_packet=op.Packet(\n",
    "        {\n",
    "            \"smooth\": op.PathSet.COLLECTION(\n",
    "                blobs=[\n",
    "                    op.Blob(\n",
    "                        kind=op.BlobKind.FILE,\n",
    "                        location=op.Uri(\n",
    "                            namespace=\"default\",\n",
    "                            path=f\"{data_dir}/smooth/config1/subj_2.csv\",\n",
    "                        ),\n",
    "                        checksum=\"\",\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            \"configs\": op.PathSet.COLLECTION(\n",
    "                blobs=[\n",
    "                    op.Blob(\n",
    "                        kind=op.BlobKind.FILE,\n",
    "                        location=op.Uri(\n",
    "                            namespace=\"default\",\n",
    "                            path=f\"{data_dir}/configs/1.json\",\n",
    "                        ),\n",
    "                        checksum=\"\",\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        }\n",
    "    ),\n",
    "    output_dir=op.Uri(namespace=\"default\", path=f\"{data_dir}/spikes\"),\n",
    "    cpu_limit=0.1,\n",
    "    memory_limit=100 << 20,\n",
    "    namespace_lookup=namespace_lookup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_run = await orch.start(namespace_lookup=namespace_lookup, pod_job=spike_pod_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbcef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_result = await orch.get_result(namespace_lookup=namespace_lookup, pod_run=pod_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec463f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await orch.delete(pod_run=pod_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e4d5f",
   "metadata": {},
   "source": [
    "## Define computational pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4996c59",
   "metadata": {},
   "source": [
    "Configuration for operator that renames packet keys i.e. `MapOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_left = {\"answer\": \"left\"}\n",
    "map_right = {\"answer\": \"right\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080cc661",
   "metadata": {},
   "source": [
    "Compute pipeline that chains a smooth operation before determining spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85936db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = op.Pipeline(\n",
    "    graph_dot=\"\"\"\n",
    "    digraph {\n",
    "        { smooth input } -> join -> spike\n",
    "    }\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        \"smooth\": op.Kernel.POD(ref=smooth_pod),\n",
    "        \"input\": op.Kernel.MAP_OPERATOR(map={}),\n",
    "        \"join\": op.Kernel.JOIN_OPERATOR(),\n",
    "        \"spike\": op.Kernel.POD(ref=spike_pod),\n",
    "    },\n",
    "    input_spec={\n",
    "        \"traces\": [op.InputSpecUri(node=\"smooth\", key=\"traces\")],\n",
    "        \"configs\": [\n",
    "            op.InputSpecUri(node=\"smooth\", key=\"configs\"),\n",
    "            op.InputSpecUri(node=\"input\", key=\"configs\"),\n",
    "        ],\n",
    "    },\n",
    "    output_spec={\"answer\": op.OutputSpecUri(node=\"spike\", key=\"spikes\")},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6af60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipeline.make_dot(with_style=False))\n",
    "demo_util.display_dot(dot_data=pipeline.make_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaea365",
   "metadata": {},
   "source": [
    "## Run computational pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93363421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = op.PipelineJob(\n",
    "    pipeline=pipeline,\n",
    "    input_packet={\n",
    "        \"traces\": [\n",
    "            op.PathSet.COLLECTION(\n",
    "                blobs=[\n",
    "                    op.Blob(\n",
    "                        kind=op.BlobKind.FILE,\n",
    "                        location=op.Uri(\n",
    "                            namespace=\"default\",\n",
    "                            path=f\"{data_dir}/subjects/{i}.csv\",\n",
    "                        ),\n",
    "                        checksum=\"\",\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            for i in range(1, NUM_FILES + 1)\n",
    "        ],\n",
    "        \"configs\": [\n",
    "            op.PathSet.COLLECTION(\n",
    "                blobs=[\n",
    "                    op.Blob(\n",
    "                        kind=op.BlobKind.FILE,\n",
    "                        location=op.Uri(\n",
    "                            namespace=\"default\",\n",
    "                            path=f\"{data_dir}/configs/{i}.json\",\n",
    "                        ),\n",
    "                        checksum=\"\",\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            for i in (1, 2)\n",
    "        ],\n",
    "    },\n",
    "    output_dir=op.Uri(namespace=\"default\", path=f\"{data_dir}/spike_pipeline\"),\n",
    "    namespace_lookup=namespace_lookup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_job.input_packet()\n",
    "pipeline_job.input_packet()[\"traces\"][0].blobs[0].checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5737e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = await client.start_pipeline_job(pipeline_job=pipeline_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"created\": pipeline_run.created(),\n",
    "    \"status\": pipeline_run.status(),\n",
    "    \"terminated\": pipeline_run.terminated(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_util.animate_display(\n",
    "    next_display_object=lambda: (\n",
    "        demo_util.display_dot(dot_data=pipeline_run.summarize_dot())\n",
    "        if not pipeline_run.terminated()\n",
    "        or datetime.now(timezone.utc).timestamp() <= pipeline_run.terminated() + 2\n",
    "        else None\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_result = await client.get_pipeline_result(pipeline_run=pipeline_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c310ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"created\": pipeline_result.created,\n",
    "    \"status\": pipeline_result.status,\n",
    "    \"terminated\": pipeline_result.terminated,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipeline_run.summarize_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecca3c",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "- Educational / Pitching Content\n",
    "- Simpler, python-friendly experience\n",
    "- Pipeline of pipelines\n",
    "- Kubernetes orchestrator\n",
    "- Queries and data exploration\n",
    "- Dashboard GUIs\n",
    "- Multi-agent support\n",
    "- Tags\n",
    "- Memoization\n",
    "- Filter operator\n",
    "- Agent resource limits\n",
    "- Support external extensibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8cc2e",
   "metadata": {},
   "source": [
    "## Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(Path(namespace_lookup[\"default\"]) / store_dir)\n",
    "shutil.rmtree(Path(namespace_lookup[\"default\"]) / data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a717ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel between notebooks to shutdown active agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f044c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
