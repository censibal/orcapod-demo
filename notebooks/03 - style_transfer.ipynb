{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3634443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orcapod as op\n",
    "from demo_setup.config import namespace_lookup, data_dir, store_dir, orch, client\n",
    "import demo_setup.util as demo_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c78d37",
   "metadata": {},
   "source": [
    "## Orcapod DEMO\n",
    "\n",
    "A framework for fully traceable and reproducible scientific computation\n",
    "\n",
    "## Guiding Principles\n",
    "\n",
    "- Reproducibility\n",
    "- Performance\n",
    "- Simplicity\n",
    "- Flexibility\n",
    "- Extensibility\n",
    "- Reusability\n",
    "- Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b0d8a",
   "metadata": {},
   "source": [
    "## Monitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor active containers\n",
    "\n",
    "# watch -n 0.5 docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d304154",
   "metadata": {},
   "source": [
    "## Setup test inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073aa09c",
   "metadata": {},
   "source": [
    "- `data_lake/models`: Painting style models used as input\n",
    "- `data_lake/subjects`: Subject images used as input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e829b",
   "metadata": {},
   "source": [
    "`display_images` - Python function that:\n",
    "- Displays images from the given directory\n",
    "- Arranges images with 3 images per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530889e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "def display_images(dir_path: str, per_row: int = 3, width: int = 250):\n",
    "    dir_path = Path(dir_path)\n",
    "    images = list(dir_path.rglob(\"*.jpeg\"))\n",
    "\n",
    "    html = '<div style=\"display:flex; flex-direction:column; gap:10px;\">'\n",
    "    for i in range(0, len(images), per_row):\n",
    "        html += '<div style=\"display:flex; gap:10px;\">'\n",
    "        for img_path in images[i:i+per_row]:\n",
    "            html += f'<img src=\"{img_path}\" width=\"{width}\">'\n",
    "        html += '</div>'\n",
    "    html += '</div>'\n",
    "\n",
    "    display(HTML(html))\n",
    "    \n",
    "display_images(\"../data_lake/subjects\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b0a20",
   "metadata": {},
   "source": [
    "## Define computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad01f96",
   "metadata": {},
   "source": [
    "`style_transfer_pod` - Python computation that:\n",
    "- Reads a subject image\n",
    "- Reads a painting style model\n",
    "- Generates a new image that applies painting style to subject image\n",
    "- Sleeps randomly between 0 - 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ebedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_transfer_pod = op.Pod(\n",
    "    image=\"demisto/opencv:1.0.0.4855524\",\n",
    "    command=[\n",
    "        \"bash\",\n",
    "        \"-c\",\n",
    "        \"umask u=rwx,g=rwx,o=rwx && python -c '{}'\".format(\n",
    "            dedent(\n",
    "                \"\"\"\n",
    "                import os\n",
    "                import cv2\n",
    "                import numpy as np\n",
    "                import imutils\n",
    "                from time import sleep\n",
    "                from random import randint\n",
    "\n",
    "                sleep(randint(0, 10))\n",
    "\n",
    "                with open(\"/input/subject.jpeg\", \"rb\") as f:\n",
    "                    image = f.read()\n",
    "\n",
    "                net = cv2.dnn.readNetFromTorch(\"/input/model.t7\")\n",
    "                prepared_image = np.frombuffer(image, np.uint8)\n",
    "                prepared_image = cv2.imdecode(prepared_image, cv2.IMREAD_COLOR)\n",
    "\n",
    "                prepared_image = imutils.resize(prepared_image, width=600)\n",
    "                (h, w) = prepared_image.shape[:2]\n",
    "\n",
    "                # construct a blob from the image, set the input, and then perform a\n",
    "                # forward pass of the network\n",
    "                blob = cv2.dnn.blobFromImage(prepared_image, 1.0, (w, h),\n",
    "                    (103.939, 116.779, 123.680), swapRB=False, crop=False)\n",
    "                net.setInput(blob)\n",
    "                output = net.forward()\n",
    "\n",
    "                # reshape the output tensor, add back in the mean subtraction, and\n",
    "                # then swap the channel ordering\n",
    "                output = output.reshape((3, output.shape[2], output.shape[3]))\n",
    "                output[0] += 103.939\n",
    "                output[1] += 116.779\n",
    "                output[2] += 123.680\n",
    "                output = output.transpose(1, 2, 0)\n",
    "                output = np.clip(output, 0, 255)\n",
    "                output= output.astype(\"uint8\")\n",
    "\n",
    "                with open(\"/output/image.jpeg\", \"wb\") as f:\n",
    "                    f.write(cv2.imencode(\".jpeg\", output)[1].tobytes())\n",
    "\n",
    "                print(\"done!\")\n",
    "                \"\"\"\n",
    "            ).strip()\n",
    "        ),\n",
    "    ],\n",
    "    input_spec={\n",
    "        \"subject\": op.PathInfo(path=\"/input/subject.jpeg\", match_pattern=\".*\\.jpeg\"),\n",
    "        \"model\": op.PathInfo(path=\"/input/model.t7\", match_pattern=\".*\\.t7\"),\n",
    "    },\n",
    "    output_dir=\"/output\",\n",
    "    output_spec={\"image\": op.PathInfo(path=\"image.jpeg\", match_pattern=\".*\\.jpeg\")},\n",
    "    source_commit_url=\"https://place.holder\",\n",
    "    recommended_cpus=1.0,\n",
    "    recommended_memory=1 << 30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5494909",
   "metadata": {},
   "source": [
    "`flip_pod` - Bash computation that:\n",
    "- Reads an image\n",
    "- Generates a horizontally flipped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_pod = op.Pod(\n",
    "    image=\"dpokidov/imagemagick:7.1.1-47\",\n",
    "    command=\"magick /input/image.jpeg -flop /output/flipped_image.jpeg\".split(\" \"),\n",
    "    input_spec={\n",
    "        \"image\": op.PathInfo(path=\"/input/image.jpeg\", match_pattern=\".*\\.jpeg\")\n",
    "    },\n",
    "    output_dir=\"/output\",\n",
    "    output_spec={\n",
    "        \"flipped_image\": op.PathInfo(\n",
    "            path=\"flipped_image.jpeg\", match_pattern=\".*\\.jpeg\"\n",
    "        )\n",
    "    },\n",
    "    source_commit_url=\"https://place.holder\",\n",
    "    recommended_cpus=0.1,\n",
    "    recommended_memory=100 << 20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e4d5f",
   "metadata": {},
   "source": [
    "## Define computational pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5ba61",
   "metadata": {},
   "source": [
    "A simple compute pipeline that chains a `style_transfer_pod` computation to a `flip_pod` computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85936db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = op.Pipeline(\n",
    "    graph_dot=\"\"\"\n",
    "    digraph {\n",
    "        style_transfer -> flip\n",
    "    }\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        \"style_transfer\": op.Kernel.POD(ref=style_transfer_pod),\n",
    "        \"flip\": op.Kernel.POD(ref=flip_pod),\n",
    "    },\n",
    "    input_spec={\n",
    "        \"subject\": [op.InputSpecUri(node=\"style_transfer\", key=\"subject\")],\n",
    "        \"model\": [op.InputSpecUri(node=\"style_transfer\", key=\"model\")],\n",
    "    },\n",
    "    output_spec={\"resultant_image\": op.OutputSpecUri(node=\"flip\", key=\"flipped_image\")},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6af60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_util.display_dot(dot_data=pipeline.make_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaea365",
   "metadata": {},
   "source": [
    "## Run computational pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93363421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = op.PipelineJob(\n",
    "    pipeline=pipeline,\n",
    "    input_packet={\n",
    "        \"subject\": [\n",
    "            op.PathSet.UNARY(\n",
    "                blob=op.Blob(\n",
    "                    kind=op.BlobKind.FILE,\n",
    "                    location=op.Uri(\n",
    "                        namespace=\"default\",\n",
    "                        path=path,\n",
    "                    ),\n",
    "                    checksum=\"\",\n",
    "                )\n",
    "            )\n",
    "            for path in (\n",
    "                \"subjects/dog.jpeg\",\n",
    "                \"subjects/cat.jpeg\",\n",
    "                \"subjects/pyramid.jpeg\",\n",
    "            )\n",
    "        ],\n",
    "        \"model\": [\n",
    "            op.PathSet.UNARY(\n",
    "                blob=op.Blob(\n",
    "                    kind=op.BlobKind.FILE,\n",
    "                    location=op.Uri(\n",
    "                        namespace=\"default\",\n",
    "                        path=path,\n",
    "                    ),\n",
    "                    checksum=\"\",\n",
    "                )\n",
    "            )\n",
    "            for path in (\"models/mosaic.t7\", \"models/starry_night.t7\")\n",
    "        ],\n",
    "    },\n",
    "    output_dir=op.Uri(namespace=\"default\", path=f\"{data_dir}/style_transfer_pipeline\"),\n",
    "    namespace_lookup=namespace_lookup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5737e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = await client.start_pipeline_job(pipeline_job=pipeline_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_util.animate_display(\n",
    "    next_display_object=lambda: (\n",
    "        demo_util.display_dot(dot_data=pipeline_run.summarize_dot())\n",
    "        if not pipeline_run.terminated()\n",
    "        or datetime.now(timezone.utc).timestamp() <= pipeline_run.terminated() + 2\n",
    "        else None\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_result = await client.get_pipeline_result(pipeline_run=pipeline_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c310ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"created\": pipeline_result.created,\n",
    "    \"status\": pipeline_result.status,\n",
    "    \"terminated\": pipeline_result.terminated,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de44b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(\"../data_lake/subjects\")\n",
    "display_images(\"../data_lake/data/style_transfer_pipeline/flip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecca3c",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "- Educational / Pitching Content\n",
    "- Simpler, python-friendly experience\n",
    "- Pipeline of pipelines\n",
    "- Kubernetes orchestrator\n",
    "- Queries and data exploration\n",
    "- Dashboard GUIs\n",
    "- Multi-agent support\n",
    "- Tags\n",
    "- Memoization\n",
    "- Filter operator\n",
    "- Agent resource limits\n",
    "- Support external extensibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8cc2e",
   "metadata": {},
   "source": [
    "## Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(Path(namespace_lookup[\"default\"]) / store_dir)\n",
    "shutil.rmtree(Path(namespace_lookup[\"default\"]) / data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a717ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel between notebooks to shutdown active agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78d803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
